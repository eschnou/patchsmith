"""Vulnerability brainstorming agent for intelligent query targeting."""

import json
from pathlib import Path
from typing import Any

from claude_agent_sdk import ClaudeAgentOptions, ClaudeSDKClient, create_sdk_mcp_server, tool

from patchsmith.adapters.claude.agent import AgentError, BaseAgent
from patchsmith.models.finding import Severity
from patchsmith.models.project import VulnerabilitySuggestion
from patchsmith.utils.logging import get_logger

logger = get_logger()


class VulnerabilityBrainstormAgent(BaseAgent):
    """Agent for brainstorming project-specific vulnerabilities to target.

    This agent analyzes project structure, code patterns, frameworks, and
    architecture to suggest relevant security vulnerabilities that should
    be targeted with custom CodeQL queries.

    Unlike the static hardcoded list, this agent:
    - Examines actual project files and dependencies
    - Identifies project type (web app, browser extension, CLI, etc.)
    - Researches common vulnerabilities for detected frameworks
    - Provides evidence-based suggestions with reasoning
    """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        """Initialize vulnerability brainstorm agent with result storage."""
        super().__init__(*args, **kwargs)
        self._suggestions: list[dict] | None = None

    def _create_submit_tool(self) -> Any:
        """Create submit_suggestions tool with closure to access instance state.

        Returns:
            Tool function that can access self._suggestions
        """
        # Capture self in closure
        agent_instance = self

        @tool(
            "submit_suggestions",
            "Submit vulnerability suggestions for custom query generation",
            {
                "suggestions": list,  # List of {vulnerability_type, language, severity, reasoning, confidence, evidence}
            },
        )
        async def submit_suggestions_tool(args: dict) -> dict:
            """Tool for submitting vulnerability suggestions."""
            suggestions_data = args.get("suggestions", [])

            # Handle case where suggestions might be a JSON string
            if isinstance(suggestions_data, str):
                try:
                    suggestions_data = json.loads(suggestions_data)
                except json.JSONDecodeError:
                    logger.error(
                        "submit_suggestions_tool_invalid_json",
                        data=suggestions_data[:200],
                    )
                    suggestions_data = []

            # Handle case where a single dict was submitted instead of a list
            if isinstance(suggestions_data, dict):
                logger.info(
                    "submit_suggestions_single_dict",
                    message="Received single dict, wrapping in list",
                )
                suggestions_data = [suggestions_data]

            # Store in instance variable
            agent_instance._suggestions = suggestions_data

            logger.debug(
                "submit_suggestions_received",
                type=type(suggestions_data).__name__,
                count=len(suggestions_data) if isinstance(suggestions_data, list) else 0,
            )

            logger.info(
                "suggestions_submitted",
                count=len(suggestions_data),
                vulnerabilities=[
                    s.get("vulnerability_type") if isinstance(s, dict) else str(s)
                    for s in suggestions_data[:5]
                ],
            )

            return {
                "content": [
                    {
                        "type": "text",
                        "text": f"Successfully recorded {len(suggestions_data)} vulnerability suggestion(s)",
                    }
                ]
            }

        return submit_suggestions_tool

    def get_system_prompt(self) -> str:
        """Get system prompt for vulnerability brainstorming."""
        return """You are a security vulnerability analysis expert specializing in identifying relevant security risks for specific projects.

Your task is to analyze a codebase and suggest relevant vulnerability types that should be targeted with custom security queries.

AVAILABLE TOOLS:
- Glob: List files matching patterns (e.g., "**/*.py", "package.json", "manifest.json")
- Read: Read file contents to examine code, configs, dependencies
- Grep: Search for specific patterns (e.g., "postMessage", "eval(", "dangerouslySetInnerHTML")
- WebSearch: Search for common vulnerabilities for detected frameworks/technologies
- WebFetch: Look up vulnerability documentation and examples
- submit_suggestions: Submit your vulnerability suggestions (YOU MUST call this with results)

RECOMMENDED WORKFLOW:
1. **Identify Project Type**
   - Use Glob to find key files (package.json, manifest.json, requirements.txt, etc.)
   - Read config files to understand project structure
   - Determine: web app, browser extension, CLI tool, API server, library, mobile app, etc.

2. **Detect Frameworks & Technologies**
   - Read package.json/requirements.txt for dependencies
   - Identify frameworks (React, Vue, Express, Flask, Django, etc.)
   - Note security-relevant packages

3. **Search for Security-Sensitive Patterns**
   - Use Grep to find dangerous functions (eval, exec, innerHTML, dangerouslySetInnerHTML)
   - Search for common vulnerability patterns (SQL queries, file operations, network calls)
   - Look for authentication/authorization code

4. **Research Framework-Specific Vulnerabilities**
   - Use WebSearch to find "common [framework] security vulnerabilities"
   - Use WebFetch to read security guides for detected technologies

5. **Suggest Relevant Vulnerabilities**
   - Focus on vulnerabilities actually present in THIS project
   - Prioritize based on project domain (e.g., browser extension → postMessage validation)
   - Provide evidence (file paths, pattern counts)
   - Call submit_suggestions with your findings

VULNERABILITY SUGGESTION FORMAT:
Call submit_suggestions with an array of suggestion objects:

```json
{
  "suggestions": [
    {
      "vulnerability_type": "postMessage origin validation bypass",
      "language": "typescript",
      "severity": "critical",
      "reasoning": "Found 47 postMessage calls in content scripts without origin validation...",
      "confidence": 0.95,
      "evidence": ["packages/extension/src/inpage/messageActions.ts:21", "postMessage usage found in 8 files"]
    },
    {
      "vulnerability_type": "XSS in React component props",
      "language": "typescript",
      "severity": "high",
      "reasoning": "React components using dangerouslySetInnerHTML detected...",
      "confidence": 0.85,
      "evidence": ["packages/extension/src/ui/components/RichText.tsx:45", "3 instances of dangerouslySetInnerHTML"]
    }
  ]
}
```

Each suggestion must include:
- vulnerability_type: Clear, specific name
- language: Target language (python, javascript, typescript, etc.)
- severity: "critical", "high", "medium", "low", or "info"
- reasoning: Why this is relevant to THIS project (2-3 sentences)
- confidence: 0.0-1.0 score
- evidence: List of specific findings (file paths, patterns, counts)

IMPORTANT GUIDELINES:
- DO NOT suggest generic vulnerabilities irrelevant to the project
  - Example: Don't suggest "SQL injection" if no database is detected
  - Example: Don't suggest "XSS" if project is a CLI tool with no HTML
- DO suggest domain-specific vulnerabilities
  - Browser extension → postMessage validation, content script XSS, extension API misuse
  - Web API → authentication bypass, injection attacks, SSRF
  - CLI tool → command injection, path traversal, arbitrary file read
- Provide EVIDENCE from actual files you examined
- Aim for 5-10 high-quality, relevant suggestions

After thorough analysis, call submit_suggestions with your results.
"""

    async def execute(  # type: ignore[override]
        self,
        project_path: Path,
        languages: list[str],
        project_context: str,
        max_suggestions: int = 10,
    ) -> list[VulnerabilitySuggestion]:
        """
        Brainstorm relevant vulnerabilities for a project.

        Args:
            project_path: Path to project directory
            languages: Detected languages in project
            project_context: Basic project context (frameworks, structure)
            max_suggestions: Maximum number of suggestions to generate

        Returns:
            List of vulnerability suggestions sorted by confidence

        Raises:
            AgentError: If brainstorming fails
        """
        # Reset instance results
        self._suggestions = None

        logger.info(
            "vulnerability_brainstorming_started",
            agent=self.agent_name,
            project_path=str(project_path),
            languages=languages,
        )

        try:
            # Create MCP server with custom tool
            submit_tool = self._create_submit_tool()
            server = create_sdk_mcp_server(
                name="vulnerability-brainstorm",
                version="1.0.0",
                tools=[submit_tool],
            )

            # Build analysis prompt
            prompt = self._build_analysis_prompt(
                project_path, languages, project_context, max_suggestions
            )

            # Configure options with tools
            options = ClaudeAgentOptions(
                system_prompt=self.get_system_prompt(),
                max_turns=100,  # Allow thorough exploration
                allowed_tools=[
                    "Read",
                    "Glob",
                    "Grep",
                    "WebSearch",
                    "WebFetch",
                    "mcp__vulnerability-brainstorm__submit_suggestions",
                ],
                mcp_servers={"vulnerability-brainstorm": server},
                cwd=str(self.working_dir),
            )

            # Query Claude with custom client
            turn_count = 0
            async with ClaudeSDKClient(options=options) as client:
                await client.query(prompt)

                async for message in client.receive_response():
                    message_type = type(message).__name__

                    # Track turns for progress
                    if message_type == "AssistantMessage":
                        turn_count += 1
                        if self.progress_callback:
                            self.progress_callback(turn_count, options.max_turns)

                    # Extract and emit thinking updates
                    thinking = self._extract_thinking_from_message(message)
                    if thinking:
                        self._emit_thinking(thinking)

            # Check if tool was called
            if self._suggestions is None:
                raise AgentError(
                    "Agent did not call submit_suggestions tool - check max_turns or prompt"
                )

            # Convert to VulnerabilitySuggestion objects
            suggestions = self._parse_suggestions(self._suggestions)

            # Sort by confidence (highest first)
            suggestions.sort(key=lambda s: s.confidence, reverse=True)

            logger.info(
                "vulnerability_brainstorming_completed",
                agent=self.agent_name,
                suggestions_count=len(suggestions),
                top_vulnerabilities=[s.vulnerability_type for s in suggestions[:5]],
            )

            return suggestions

        except Exception as e:
            logger.error(
                "vulnerability_brainstorming_failed",
                agent=self.agent_name,
                error=str(e),
            )
            raise AgentError(f"Vulnerability brainstorming failed: {e}") from e

    def _build_analysis_prompt(
        self,
        project_path: Path,
        languages: list[str],
        project_context: str,
        max_suggestions: int,
    ) -> str:
        """
        Build prompt for vulnerability brainstorming.

        Args:
            project_path: Project directory path
            languages: Detected languages
            project_context: Basic project context
            max_suggestions: Maximum suggestions to generate

        Returns:
            Analysis prompt text
        """
        return f"""Analyze this project and suggest relevant security vulnerabilities to target with custom CodeQL queries.

PROJECT INFORMATION:
- Path: {project_path}
- Languages: {', '.join(languages)}
- Context: {project_context}

TASK:
Thoroughly analyze this project to identify {max_suggestions} relevant security vulnerabilities that should be detected with custom queries.

Use your tools to:
1. Understand the project type and architecture
2. Identify frameworks and technologies used
3. Find security-sensitive code patterns
4. Research common vulnerabilities for detected technologies
5. Suggest specific, relevant vulnerabilities with evidence

Focus on vulnerabilities that are:
- Actually relevant to THIS project (not generic)
- Specific to detected frameworks/patterns
- Backed by evidence from your analysis
- Prioritized by severity and likelihood

After your analysis, call submit_suggestions with your findings.
"""

    def _parse_suggestions(
        self, suggestions: list[dict]
    ) -> list[VulnerabilitySuggestion]:
        """
        Parse tool results into VulnerabilitySuggestion objects.

        Args:
            suggestions: Raw suggestion data from tool

        Returns:
            List of VulnerabilitySuggestion objects
        """
        # Handle case where a single dict was passed
        if isinstance(suggestions, dict):
            logger.info(
                "parse_suggestions_wrapping_dict",
                message="Received dict, wrapping in list",
            )
            suggestions = [suggestions]

        if not isinstance(suggestions, list):
            logger.warning(
                "parse_suggestions_invalid_type",
                type=type(suggestions).__name__,
                data=str(suggestions)[:200],
            )
            return []

        try:
            parsed_suggestions: list[VulnerabilitySuggestion] = []

            for idx, item in enumerate(suggestions):
                try:
                    if not isinstance(item, dict):
                        logger.warning(
                            "suggestion_item_invalid_type",
                            index=idx,
                            type=type(item).__name__,
                        )
                        continue

                    # Map severity string to Severity enum
                    severity_str = item.get("severity", "medium").lower()
                    severity_map = {
                        "critical": Severity.CRITICAL,
                        "high": Severity.HIGH,
                        "medium": Severity.MEDIUM,
                        "low": Severity.LOW,
                        "info": Severity.INFO,
                    }
                    severity = severity_map.get(severity_str, Severity.MEDIUM)

                    # Create VulnerabilitySuggestion object
                    suggestion = VulnerabilitySuggestion(
                        vulnerability_type=item.get("vulnerability_type", "Unknown"),
                        language=item.get("language", "unknown"),
                        severity=severity,
                        reasoning=item.get("reasoning", "No reasoning provided"),
                        confidence=float(item.get("confidence", 0.5)),
                        evidence=item.get("evidence", []),
                    )
                    parsed_suggestions.append(suggestion)

                    logger.debug(
                        "suggestion_parsed",
                        index=idx,
                        vulnerability=suggestion.vulnerability_type,
                        language=suggestion.language,
                        confidence=suggestion.confidence,
                    )

                except Exception as e:
                    logger.warning(
                        "suggestion_parse_failed",
                        index=idx,
                        error=str(e),
                        item=str(item)[:200],
                    )
                    continue

            logger.info(
                "suggestions_parsed",
                total_raw=len(suggestions),
                total_parsed=len(parsed_suggestions),
            )

            return parsed_suggestions

        except Exception as e:
            logger.error(
                "parse_suggestions_failed",
                error=str(e),
            )
            return []
